{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import ones_state, vis, state_ones\n",
    "\n",
    "cam = cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aabdo\\miniconda3\\envs\\tic_tac_toe\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created with # params: 507858\n",
      "loading model weights from path: weights-00-0.28.hdf5\n",
      "loaded weights\n"
     ]
    }
   ],
   "source": [
    "from detector import Detector\n",
    "d = Detector(64, 64, \"weights-00-0.28.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created with # params: 353\n",
      "loading model weights from path: t3_weights-19-0.24.hdf5\n",
      "loaded weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aabdo\\miniconda3\\envs\\tic_tac_toe\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create tictac ai\n",
    "import t3_ai\n",
    "t3 = t3_ai.AI(weights_path=\"t3_weights-19-0.24.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc_from_int(a):\n",
    "    r = int(np.floor(a/3.0))\n",
    "    c = a%3\n",
    "    return r,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "O O X \n",
      "X X - \n",
      "O - X \n",
      "[(230, 251), (432, 453)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "# now let's initialize the list of reference point\n",
    "ref_point = []\n",
    "draw = False\n",
    "def shape_selection(event, x, y, flags, param):\n",
    "    # grab references to the global variables\n",
    "    global ref_point, crop, draw\n",
    "    # ix, iy = (0, 0)\n",
    "    # if the left mouse button was clicked, record the starting\n",
    "    # (x, y) coordinates and indicate that cropping is being performed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        draw = True\n",
    "        ref_point = [(x, y)]\n",
    "        # image = clone.copy()\n",
    "        # cv2.imshow(\"image\", image)\n",
    "\n",
    "    # check to see if the left mouse button was released\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        # record the ending (x, y) coordinates and indicate that\n",
    "        # the cropping operation is finished\n",
    "        if draw:\n",
    "            draw = False\n",
    "            ref_point.append((x, y))\n",
    "            ix, iy = (ref_point[0][0], ref_point[0][1])\n",
    "            # calculate the side length of the square\n",
    "            side_length = max(abs(x - ix), abs(y - iy))\n",
    "\n",
    "            # determine the bottom-right corner of the square\n",
    "            if x >= ix and y >= iy:\n",
    "                ref_point[1] = (ix + side_length, iy + side_length)\n",
    "            elif x >= ix and y < iy:\n",
    "                ref_point[1] = (ix + side_length, iy - side_length)\n",
    "            elif x < ix and y >= iy:\n",
    "                ref_point[1] = (ix - side_length, iy + side_length)\n",
    "            else:\n",
    "                ref_point[1] = (ix - side_length, iy - side_length)\n",
    "\n",
    "                        \n",
    "            # cv2.imshow(\"image\", image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load the image, clone it, and setup the mouse callback function\n",
    "ret_val, image = cam.read()\n",
    "# image = cv2.imread('download.png')\n",
    "clone = image.copy()\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.setMouseCallback(\"image\", shape_selection)\n",
    "\n",
    "croped_img = None\n",
    "# keep looping until the 'q' key is pressed\n",
    "rotation = 0\n",
    "while True:\n",
    "    # display the image and wait for a keypress\n",
    "    ret_val, image = cam.read()\n",
    "    for _ in range(rotation):\n",
    "        image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "    \n",
    "    if len(ref_point)==2:\n",
    "        # draw a square around the region of interest\n",
    "        thickness = 2\n",
    "        cv2.rectangle(image, \n",
    "                (ref_point[0][0] - thickness, ref_point[0][1] - thickness), \n",
    "                (ref_point[1][0] + thickness, ref_point[1][1] + thickness), \n",
    "                (0, 255, 0), thickness)\n",
    "        croped_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        croped_img = croped_img[ref_point[0][1]:ref_point[1][1], ref_point[0][0]:ref_point[1][0]]\n",
    "        croped_img = cv2.resize(croped_img, (64, 64))\n",
    "        croped_img = cv2.adaptiveThreshold(croped_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11,2)\n",
    "        croped_img = 255-croped_img\n",
    "        croped_img = croped_img.astype(np.float64)\n",
    "        croped_img /= 255\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        cv2.imshow(\"cropped\", cv2.resize(croped_img, (256, 256)))\n",
    "        # plt.imshow(croped_img, cmap=plt.cm.gray)\n",
    "        state = np.round(d.predict(croped_img))\n",
    "        vis(ones_state(state))\n",
    "        state = ones_state(state)\n",
    "        # besta = t3.best_move(state)\n",
    "        # r, c = rc_from_int(besta)\n",
    "        # print(r,c)\n",
    "    \n",
    "    cv2.imshow(\"image\", image)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # press 'r' to reset the window\n",
    "    if key == ord(\"r\"):\n",
    "        # draw = True\n",
    "        rotation += 1\n",
    "        rotation %= 4\n",
    "        # image = clone.copy()\n",
    "\n",
    "    # if the 'c' key is pressed, break from the loop\n",
    "    elif key == 27:\n",
    "        break\n",
    "\n",
    "# close all open windows\n",
    "print(ref_point)\n",
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
